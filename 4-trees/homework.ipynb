{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VXOHnGycvwJ5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from scipy.special import expit\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bdJi9Zb8aqS0"
      },
      "outputs": [],
      "source": [
        "heart_data = pd.read_csv(\"heart_cleveland.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "H1gK6NdMa2rl",
        "outputId": "2c734e29-1970-4506-8d50-72c661151fb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>234</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>282</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>211</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
              "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
              "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
              "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
              "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
              "\n",
              "   ca  thal  condition  \n",
              "0   1     0          0  \n",
              "1   2     0          0  \n",
              "2   0     0          0  \n",
              "3   1     0          1  \n",
              "4   0     0          0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uqB1_eSgbCvc"
      },
      "outputs": [],
      "source": [
        "# Функция для расчета энтропии в выборке\n",
        "def calculate_entropy(y):\n",
        "    # Получаем уникальные классы и их частоты в выборке\n",
        "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "    total_samples = ...\n",
        "\n",
        "    # Рассчитываем вероятности для каждого класса, \n",
        "    # в class counts уже лежит то, что нужно - массив из встречаемости классов\n",
        "    probabilities = class_counts / \n",
        "\n",
        "    # Рассчитываем энтропию по формуле Шеннона, для логарифма можем использовать np.log2\n",
        "    entropy = -np.sum( ... * ...)\n",
        "    return entropy\n",
        "\n",
        "# Функция для поиска оптимального разделения (сплита) на основе энтропии\n",
        "def find_best_split(X, y):\n",
        "    # Получаем количество образцов (m) и количество признаков (n)\n",
        "    m, n = X.shape\n",
        "\n",
        "    # Инициализируем переменные для хранения лучшего сплита\n",
        "    best_entropy = float('inf')\n",
        "    best_split = None\n",
        "\n",
        "    # Перебираем все признаки\n",
        "    for feature_index in range(n):\n",
        "        # Получаем уникальные значения признака\n",
        "        unique_values = np.unique(X[:, feature_index])\n",
        "\n",
        "        # Перебираем все уникальные значения в качестве порога (threshold)\n",
        "        for threshold in unique_values:\n",
        "            # Создаем маску для разделения данных на две части\n",
        "            mask_left = X[:, feature_index] <= threshold\n",
        "            # маска - массив из True\\False, который бы указывал к левой или правой части \n",
        "            # сплита относится элемент под этим индексом\n",
        "            # логично, что все элементы, что не попали в левую группу, попадают в правую\n",
        "            mask_right = ~mask_left\n",
        "\n",
        "            # Рассчитываем энтропию для левой и правой частей\n",
        "            left_group = y[mask_left]\n",
        "            right_group = y[mask_right]\n",
        "\n",
        "            entropy_left = calculate_entropy(...)\n",
        "            entropy_right = calculate_entropy(...)\n",
        "\n",
        "            # Рассчитываем среднюю взвешенную энтропию\n",
        "            total_samples = ...\n",
        "            # вес левой и правой группы = (сколько в группе элементов)/ (сколько элементов было до сплита)\n",
        "            weight_left = ...\n",
        "            weight_right = ...\n",
        "            # считаем взвешенную энтропию сплита (нужно домножить энтропию каждой группы на ее вес)\n",
        "            split_entropy = ...\n",
        "\n",
        "            # Если текущий сплит улучшает энтропию, обновляем лучший сплит\n",
        "            if split_entropy < best_entropy:\n",
        "                best_entropy = split_entropy\n",
        "                best_split = {\n",
        "                    'feature_index': feature_index,\n",
        "                    'threshold': threshold,\n",
        "                    'entropy': split_entropy\n",
        "                }\n",
        "\n",
        "    return best_split # Возвращаем информацию о лучшем сплите"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ps-MTXw6bSe1"
      },
      "outputs": [],
      "source": [
        "# Выделяем признаки и целевую переменную\n",
        "X = heart_data.drop('condition', axis=1)\n",
        "y = heart_data['condition']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-NLXsTbgcK0h"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._fit(X, y, depth=0)\n",
        "\n",
        "    def _fit(self, X, y, depth):\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Критерий остановки 1: Если все элементы принадлежат одному классу\n",
        "        if len(unique_classes) == 1:\n",
        "            return {'class': unique_classes[0]}\n",
        "\n",
        "        # Критерий остановки 2: Достигнута максимальная глубина\n",
        "        if self.max_depth is not None and depth == self.max_depth:\n",
        "            return {'class': self._most_common_class(y)}\n",
        "\n",
        "        # Критерий остановки 3: Если нет признаков для разделения\n",
        "        if X.shape[1] == 0:\n",
        "            return {'class': self._most_common_class(y)}\n",
        "\n",
        "        # Находим лучший сплит\n",
        "        best_split = ...\n",
        "\n",
        "        # Критерий остановки 4: Если не удалось найти оптимальный сплит\n",
        "        if best_split is None:\n",
        "            return {'class': self._most_common_class(y)}\n",
        "        # кажется мы это видели в best_split?\n",
        "        feature_index = ...\n",
        "        threshold = ...\n",
        "\n",
        "        # Разделяем данные на две части\n",
        "        mask_left = X[:, feature_index] <= threshold\n",
        "        mask_right = ~mask_left\n",
        "\n",
        "        # Рекурсивно строим поддеревья\n",
        "        subtree_left = self._fit(X[mask_left], y[mask_left], depth + 1)\n",
        "        subtree_right = self._fit(X[mask_right], y[mask_right], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'feature_index': feature_index,\n",
        "            'threshold': threshold,\n",
        "            'subtree_left': subtree_left,\n",
        "            'subtree_right': subtree_right\n",
        "        }\n",
        "\n",
        "    def _most_common_class(self, y):\n",
        "        unique_classes, counts = np.unique(y, return_counts=True)\n",
        "        return unique_classes[np.argmax(counts)]\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.array([self._predict_single(x, self.tree) for x in X])\n",
        "        return predictions\n",
        "\n",
        "    def _predict_single(self, x, node):\n",
        "        if 'class' in node:\n",
        "            return node['class']\n",
        "\n",
        "        if x[node['feature_index']] <= node['threshold']:\n",
        "            return self._predict_single(x, node['subtree_left'])\n",
        "        else:\n",
        "            return self._predict_single(x, node['subtree_right'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gVZ-ctHechlO"
      },
      "outputs": [],
      "source": [
        "# Разбиваем данные на обучающий и тестовый набор\n",
        "X_train, X_test, y_train, y_test = \n",
        "\n",
        "# Обучаем дерево\n",
        "tree_classifier = DecisionTree(max_depth=3)\n",
        "tree_classifier.fit(X_train.values, y_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4_h7hK_Mcwec"
      },
      "outputs": [],
      "source": [
        "# Предсказываем на тестовых данных\n",
        "y_pred = tree_classifier.predict(X_test.values)\n",
        "\n",
        "# Оцениваем производительность модели\n",
        "accuracy = ...\n",
        "precision = ...\n",
        "recall = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте теперь сравним качество нашего самописного дерева с реализацией из sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "soNT0hTPc1zt"
      },
      "outputs": [],
      "source": [
        "# Создаем и обучаем модель DecisionTreeClassifier из scikit-learn\n",
        "sklearn_tree = ...\n",
        "\n",
        "...\n",
        "\n",
        "# Предсказываем на тестовых данных\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "\n",
        "# Оцениваем производительность модели\n",
        "\n",
        "accuracy_sklearn = ...\n",
        "precision_sklearn = ...\n",
        "recall_sklearn = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cdib2aPc3rP",
        "outputId": "5b36c2e0-9843-443e-a528-23c85e86ba44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom Decision Tree:\n",
            "Accuracy: 0.8266666666666667\n",
            "Precision: 0.7857142857142857\n",
            "Recall: 0.7586206896551724\n",
            "\n",
            "Sklearn Decision Tree:\n",
            "Accuracy: 0.8533333333333334\n",
            "Precision: 0.8214285714285714\n",
            "Recall: 0.7931034482758621\n"
          ]
        }
      ],
      "source": [
        "print(\"Custom Decision Tree:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"\\nSklearn Decision Tree:\")\n",
        "print(\"Accuracy:\", accuracy_sklearn)\n",
        "print(\"Precision:\", precision_sklearn)\n",
        "print(\"Recall:\", recall_sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XevRPxvae9oZ"
      },
      "source": [
        "<h1>ПРОДВИНУТАЯ ЧАСТЬ<h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7jv4S9SdTIe"
      },
      "outputs": [],
      "source": [
        "class GradientBoostingClassifier:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=None, regularization=0.1):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.regularization = regularization\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Инициализация предсказаний\n",
        "        predictions = np.zeros(len(y))\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Вычисление градиента\n",
        "            gradient = y - expit(predictions)\n",
        "\n",
        "            # Обучение дерева на остатках\n",
        "            tree = DecisionTree(max_depth=self.max_depth)\n",
        "            ...\n",
        "\n",
        "            # Применение регуляризации\n",
        "            tree.tree = self.apply_regularization(tree.tree)\n",
        "\n",
        "            # Обновление предсказаний с учетом нового дерева\n",
        "            predictions += self.learning_rate * tree.predict(X)\n",
        "\n",
        "            # Сохранение дерева\n",
        "            self.trees.append(...)\n",
        "\n",
        "    def apply_regularization(self, tree):\n",
        "        # Рекурсивно применяем регуляризацию ко всем узлам дерева\n",
        "        if 'value' in tree:\n",
        "            tree['value'] = tree['value'] / (1 + self.regularization)\n",
        "        if 'subtree_left' in tree:\n",
        "            tree['subtree_left'] = self.apply_regularization(tree['subtree_left'])\n",
        "        if 'subtree_right' in tree:\n",
        "            tree['subtree_right'] = self.apply_regularization(tree['subtree_right'])\n",
        "        return tree\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Суммируем предсказания всех деревьев\n",
        "        predictions = sum(... for tree in self.trees)\n",
        "        # Применение сигмоиды для получения вероятностей\n",
        "        probabilities = expit(predictions)\n",
        "        return ...\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        # Преобразование вероятностей в бинарные метки классов\n",
        "        return (self.predict_proba(X) >= ...).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJL83TAQfCPp"
      },
      "outputs": [],
      "source": [
        "# Инициализируем и обучаем градиентный бустинг\n",
        "gradient_boosting = ...\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW2ibc5xfIZm",
        "outputId": "9332662d-cca5-4a49-c4cd-8369bb02b99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting:\n",
            "Accuracy: 0.7666666666666667\n",
            "Precision: 0.71875\n",
            "Recall: 0.8214285714285714\n"
          ]
        }
      ],
      "source": [
        "# Предсказываем на тестовых данных\n",
        "y_pred_gb = ...\n",
        "\n",
        "# Оцениваем производительность модели\n",
        "...\n",
        "\n",
        "print(\"Gradient Boosting:\")\n",
        "print(\"Accuracy:\", accuracy_gb)\n",
        "print(\"Precision:\", precision_gb)\n",
        "print(\"Recall:\", recall_gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdt1kLZofUDJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
